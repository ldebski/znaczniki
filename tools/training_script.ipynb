{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "detector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AFFiMQ81aCe"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import IPython.display as display\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import zipfile"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wvi4PSF-kXPm"
      },
      "source": [
        "# Load and process data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1LeQA17zklu"
      },
      "source": [
        "def columns_to_y(row):\n",
        "  labels = [\"Marker1\", \"Marker2\", \"Marker3\", \"Marker4\",\n",
        "            \"ColorLeft\", \"ColorRight\", \"GrayScaleRight\", \"GreyScaleLeft\",\n",
        "            \"CircleTop\", \"CircleRight\", \"CircleBottom\", \"CircleLeft\"]\n",
        "\n",
        "  output = []\n",
        "  for label in labels:\n",
        "      for coord in eval(row[label]):\n",
        "        output.append(float(coord))\n",
        "  return output\n",
        "\n",
        "def name_to_path(row, prefix):\n",
        "  path = prefix + row[\"photoFullPath\"].split(\"/\")[-1].lower()\n",
        "  return path\n",
        "\n",
        "def load_image(row):\n",
        "  img = matplotlib.image.imread(row[\"path\"])\n",
        "  # if len(img.shape) != 3:\n",
        "  #  img = np.stack((img,)*3, axis=-1)\n",
        "  return tf.convert_to_tensor(img, dtype=tf.float32)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbPiB2ZOxG8q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "314e906e-59c4-4c48-e469-688d47d8a6f9"
      },
      "source": [
        "frames = []\n",
        "\n",
        "with zipfile.ZipFile(\"./drive/My Drive/Colab Notebooks/dataset.zip\", 'r') as zip_ref:\n",
        "  zip_ref.extractall(\".\")\n",
        "print(len(os.listdir(\"dataset\")))\n",
        "for i in range(len(os.listdir(\"dataset\"))):\n",
        "  data = pd.read_csv(\"dataset/data{}/labeled_data.csv\".format(i), sep=\"|\")\n",
        "  data[\"path\"] = data.apply(lambda row: name_to_path(row, \"./dataset/data{}/source_to_label/\".format(i)), axis=1)\n",
        "  data[\"y\"] = data.apply(lambda row: columns_to_y(row), axis=1)\n",
        "  frames.append(data[[\"path\", \"y\"]])\n",
        "\n",
        "# with zipfile.ZipFile(\"./drive/My Drive/Colab Notebooks/validation.zip\", 'r') as zip_ref:\n",
        "#     zip_ref.extractall(\".\")\n",
        "# validation_data = pd.read_csv(\"validation/data/data.txt\", sep=\"|\", usecols=[\"photoFullPath1\", \"LeftTop\", \"RightTop\", \"RightLow\", \"LeftLow\"])\n",
        "# validation_data[\"path\"] = validation_data.apply(lambda row: name_to_path(row, \"validation/\"), axis=1)\n",
        "# validation_data[\"y\"] = validation_data.apply(lambda row: columns_to_y(row), axis=1)\n",
        "# data, _ = train_test_split(validation_data, test_size=0.5)\n",
        "# frames.append(data[[\"path\", \"y\"]])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpxiqejYEqNA",
        "outputId": "c408391e-edc6-4e14-b0dd-1b362ac7e52d"
      },
      "source": [
        "data = pd.concat(frames, ignore_index=True)\n",
        "data = data.sample(frac=1).reset_index(drop=True)\n",
        "#validation_data = validation_data.sample(frac=1).reset_index(drop=True)\n",
        "data, validation_data = train_test_split(data, test_size=0.1)\n",
        "data = data.sample(frac=1).reset_index(drop=True)\n",
        "validation_data = validation_data.sample(frac=1).reset_index(drop=True)\n",
        "print(len(data))\n",
        "print(len(validation_data))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3060\n",
            "340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq2irippRoFv",
        "outputId": "94bbda53-07e8-4a20-f36c-bacbc5ac44c9"
      },
      "source": [
        "print(data)\n",
        "print(validation_data[\"y\"].iloc[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                          path                                                  y\n",
            "0      ./dataset/data7/source_to_label/397.jpg  [0.23, 0.7266666666666667, 0.2175, 0.298333333...\n",
            "1      ./dataset/data3/source_to_label/121.jpg  [0.235, 0.24833333333333332, 0.73, 0.243333333...\n",
            "2      ./dataset/data6/source_to_label/796.jpg  [0.1675, 0.8666666666666667, 0.1525, 0.1066666...\n",
            "3      ./dataset/data7/source_to_label/257.jpg  [0.235, 0.655, 0.2425, 0.15833333333333333, 0....\n",
            "4      ./dataset/data7/source_to_label/353.jpg  [0.28, 0.6933333333333334, 0.245, 0.2533333333...\n",
            "...                                        ...                                                ...\n",
            "3055   ./dataset/data6/source_to_label/756.jpg  [0.1675, 0.6683333333333333, 0.2125, 0.105, 0....\n",
            "3056  ./dataset/data11/source_to_label/113.jpg  [0.13, 0.7133333333333334, 0.1975, 0.108333333...\n",
            "3057   ./dataset/data2/source_to_label/143.jpg  [0.2175, 0.195, 0.7275, 0.19, 0.7475, 0.753333...\n",
            "3058   ./dataset/data6/source_to_label/576.jpg  [0.14, 0.7833333333333333, 0.11, 0.19666666666...\n",
            "3059    ./dataset/data8/source_to_label/66.jpg  [0.8475, 0.22333333333333333, 0.77, 0.81, 0.14...\n",
            "\n",
            "[3060 rows x 2 columns]\n",
            "[0.2925, 0.6116666666666667, 0.3275, 0.19833333333333333, 0.86, 0.33166666666666667, 0.7475, 0.87, 0.3475, 0.6733333333333333, 0.4025, 0.195, 0.7375, 0.28, 0.6425, 0.8133333333333334, 0.395, 0.45666666666666667, 0.54, 0.31333333333333335, 0.6525, 0.5866666666666667, 0.49, 0.6833333333333333]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yppLW4_RoNhx"
      },
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, df, batch_size=32, shuffle=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.df = df\n",
        "        self.indices = self.df.index.tolist()\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        batch_indices = [self.indices[k] for k in index]\n",
        "        \n",
        "        X, Y = self.__get_data(batch_indices)\n",
        "        return X, Y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.index = np.arange(len(self.indices))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.index)\n",
        "\n",
        "    def __get_data(self, batch_indices):\n",
        "        batch = self.df.iloc[batch_indices,:]\n",
        "        batch[\"image\"] = batch.apply(lambda row: load_image(row), axis=1)\n",
        "        X = tf.convert_to_tensor(batch[\"image\"].tolist())\n",
        "        Y = tf.convert_to_tensor(batch[\"y\"].tolist())\n",
        "        return X, Y\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HA2OnGP5QDk"
      },
      "source": [
        "dataset = DataGenerator(data)\n",
        "val_dataset = DataGenerator(validation_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRYbVB9zkQg5"
      },
      "source": [
        "# Create Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViA1SQrBmE1T"
      },
      "source": [
        "**Create model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fipAIHYFptnR",
        "outputId": "8ad30a8d-ea6a-45db-8d4a-11cc99a2d940"
      },
      "source": [
        "mobile_model = tf.keras.applications.MobileNetV2(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
        "\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "x = mobile_model(inputs)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(.1)(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(.1)(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(.1)(x)\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(.2)(x)\n",
        "outputs = tf.keras.layers.Dense(24, activation='sigmoid')(x)\n",
        "detector_model = tf.keras.Model(inputs, outputs)\n",
        "detector_model.compile(optimizer=\"Adam\", loss=\"mean_squared_error\")\n",
        "\n",
        "detector_model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 62720)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              64226304  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 24)                3096      \n",
            "=================================================================\n",
            "Total params: 72,424,408\n",
            "Trainable params: 72,390,296\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4VF4XEOl9oV"
      },
      "source": [
        "**Load model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a_6N2f95aTR"
      },
      "source": [
        "detector_model = tf.keras.models.load_model(\"./drive/My Drive/Colab Notebooks/mobile1.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy0h3iZh2teQ",
        "outputId": "39fa42c7-e3a8-449f-c6d8-48aa29c4052b"
      },
      "source": [
        "detector_model.evaluate(val_dataset)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 65ms/step - loss: 0.0618\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06184384226799011"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrhdvh-M6MfE",
        "outputId": "33c92f78-2cd0-4f66-da4e-d7adf584b169"
      },
      "source": [
        "detector_model.fit(dataset, validation_data=val_dataset, epochs=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            " 2/95 [..............................] - ETA: 9s - loss: 0.0925WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0573s vs `on_train_batch_end` time: 0.1427s). Check your callbacks.\n",
            "95/95 [==============================] - 22s 228ms/step - loss: 0.0311 - val_loss: 0.1281\n",
            "Epoch 2/200\n",
            "95/95 [==============================] - 22s 231ms/step - loss: 0.0090 - val_loss: 0.0523\n",
            "Epoch 3/200\n",
            "95/95 [==============================] - 22s 233ms/step - loss: 0.0068 - val_loss: 0.0796\n",
            "Epoch 4/200\n",
            "95/95 [==============================] - 22s 236ms/step - loss: 0.0061 - val_loss: 0.0139\n",
            "Epoch 5/200\n",
            "95/95 [==============================] - 23s 240ms/step - loss: 0.0061 - val_loss: 0.0340\n",
            "Epoch 6/200\n",
            "95/95 [==============================] - 23s 244ms/step - loss: 0.0059 - val_loss: 0.0308\n",
            "Epoch 7/200\n",
            "95/95 [==============================] - 23s 243ms/step - loss: 0.0053 - val_loss: 0.0658\n",
            "Epoch 8/200\n",
            "95/95 [==============================] - 23s 241ms/step - loss: 0.0049 - val_loss: 0.0087\n",
            "Epoch 9/200\n",
            "95/95 [==============================] - 23s 241ms/step - loss: 0.0046 - val_loss: 0.0120\n",
            "Epoch 10/200\n",
            "95/95 [==============================] - 23s 242ms/step - loss: 0.0042 - val_loss: 0.0313\n",
            "Epoch 11/200\n",
            "95/95 [==============================] - 23s 240ms/step - loss: 0.0045 - val_loss: 0.0393\n",
            "Epoch 12/200\n",
            "95/95 [==============================] - 23s 240ms/step - loss: 0.0088 - val_loss: 0.0728\n",
            "Epoch 13/200\n",
            "95/95 [==============================] - 23s 242ms/step - loss: 0.0088 - val_loss: 0.0774\n",
            "Epoch 14/200\n",
            "95/95 [==============================] - 23s 243ms/step - loss: 0.0080 - val_loss: 0.1944\n",
            "Epoch 15/200\n",
            "95/95 [==============================] - 23s 242ms/step - loss: 0.0061 - val_loss: 0.2282\n",
            "Epoch 16/200\n",
            "95/95 [==============================] - 23s 240ms/step - loss: 0.0066 - val_loss: 0.1583\n",
            "Epoch 17/200\n",
            "95/95 [==============================] - 23s 240ms/step - loss: 0.0064 - val_loss: 0.1040\n",
            "Epoch 18/200\n",
            "95/95 [==============================] - 23s 243ms/step - loss: 0.0052 - val_loss: 0.1092\n",
            "Epoch 19/200\n",
            "95/95 [==============================] - 23s 243ms/step - loss: 0.0053 - val_loss: 0.0867\n",
            "Epoch 20/200\n",
            "95/95 [==============================] - 23s 243ms/step - loss: 0.0049 - val_loss: 0.0640\n",
            "Epoch 21/200\n",
            "95/95 [==============================] - 23s 243ms/step - loss: 0.0047 - val_loss: 0.0720\n",
            "Epoch 22/200\n",
            "95/95 [==============================] - 23s 243ms/step - loss: 0.0048 - val_loss: 0.0514\n",
            "Epoch 23/200\n",
            "95/95 [==============================] - 23s 241ms/step - loss: 0.0047 - val_loss: 0.0498\n",
            "Epoch 24/200\n",
            "95/95 [==============================] - 23s 244ms/step - loss: 0.0043 - val_loss: 0.0427\n",
            "Epoch 25/200\n",
            "95/95 [==============================] - 23s 244ms/step - loss: 0.0044 - val_loss: 0.0391\n",
            "Epoch 26/200\n",
            "95/95 [==============================] - 23s 243ms/step - loss: 0.0043 - val_loss: 0.0444\n",
            "Epoch 27/200\n",
            "80/95 [========================>.....] - ETA: 3s - loss: 0.0040"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA9GvmVGqdIH"
      },
      "source": [
        "detector_model.save(\"./drive/My Drive/Colab Notebooks/mobile1.hdf5\")  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HWWtdHHTd80"
      },
      "source": [
        "# Tego niżej nie używamy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uqNaWq83nTJ"
      },
      "source": [
        "opt = tf.optimizers.Adam()\n",
        "\n",
        "@tf.function\n",
        "def train_step(image, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    output = detector_model(image)\n",
        "    loss = tf.math.reduce_mean(tf.math.squared_difference(y, output))\n",
        "  grad = tape.gradient(loss, detector_model.trainable_weights)\n",
        "  opt.apply_gradients(zip(grad, detector_model.trainable_weights))\n",
        "  return loss\n",
        "\n",
        "epochs = 40\n",
        "steps_per_epoch = len(dataset)\n",
        "display.display(\"loss = {}\".format(0), display_id=44484848484)\n",
        "for n in range(epochs):\n",
        "  step = 0\n",
        "  total_loss = 0\n",
        "  for m in range(steps_per_epoch):\n",
        "    step += 1 \n",
        "    image, y = dataset[m]\n",
        "    loss = train_step(image, y)\n",
        "    total_loss += loss\n",
        "    print(\".\", end='')\n",
        "    display.update_display(\"loss = {}\".format(total_loss/step), display_id=44484848484)\n",
        "  \n",
        "  detector_model.save(\"./drive/My Drive/Colab Notebooks/model1.hdf5\")\n",
        "  display.clear_output(wait=True)\n",
        "  display.display(\"epoch {}/{}\".format(n, epochs))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsQEkHrR7Kau"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}